{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjKEBdGTynHd"
   },
   "source": [
    "# Transformação de dados\n",
    "\n",
    "Código em Python para análise de dados. \n",
    "\n",
    "\n",
    "Este notebook foi desenvolvido para o ambiente GOOGLE COLAB ([colab.research.google.com](https://colab.research.google.com)).\n",
    "\n",
    "Prof. Hugo de Paula\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUYY894Qylai"
   },
   "source": [
    "# Inicialização da plataforma\n",
    "\n",
    "A célula a seguir inicializa a plataforma, carregando as bibliotecas que serão relevantes para o trabalho em seguida.\n",
    "\n",
    "## Bibliotecas\n",
    "\n",
    "\n",
    "\n",
    "```numpy``` -- usada para processamento numérico.\n",
    "\n",
    "```pandas``` -- usada para manipulação de bases de dados.\n",
    "\n",
    "```pyplot``` -- usada para visualização de dados.\n",
    "\n",
    "```seaborn``` -- usada para visualização de dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyeTED-9zxTC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numba import jit, cuda\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.set_printoptions(threshold=None, precision=2)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qbw3Lal73we2"
   },
   "source": [
    "# Base de dados do Titanic\n",
    "\n",
    "Essa base de dados pode ser obtida no Kaggle, no endereço: \n",
    "[www.kaggle.com/c/titanic/data](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "### DESCRIÇÃO DOS ATRIBUTOS:\n",
    "\n",
    "\n",
    "*   ```survival``` --  Sobrevivente (0 = Não; 1 = Sim)\n",
    "*   ```pclass``` --  Classe do passageiro (1 = 1a classe; 2 = 2a classe; 3 = 3a classe)\n",
    "*   ```name``` --  Nome (str)\n",
    "*   ```sex``` --  Sexo (male; female)\n",
    "*   ```age``` --  Idade (numérica)\n",
    "*   ```sibsp``` --  Número de irmãos/conjuges à bordo\n",
    "*   ```parch``` --  Número de pais/filhos à bordo\n",
    "*   ```ticket``` --  Número da passagem\n",
    "*   ```fare``` --  Tarifa do passageiro\n",
    "*   ```cabin``` --  Cabine\n",
    "*   ```embarked``` --  Porto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "### UPLOAD DE ARQUIVO LOCAL:\n",
    "\n",
    "Para fazer o upload de bases de dados, deve-se usar o objeto ```files``` do pacote ```goggle.colab```.\n",
    "\n",
    "Deve-se fazer o upload do arquivo \"train.csv\" disponível na pasta \"Datasets\\Titanic\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTPbeWe14a29"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oy1UjWsm5udo"
   },
   "outputs": [],
   "source": [
    "\n",
    "titanic_train = pd.read_csv(next(iter(uploaded.keys())))\n",
    "\n",
    "print(\"\\nDimensões de Titanic:\\n{0}\\n\".format(titanic_train.shape))\n",
    "print(\"\\nCampos de Titanic:\\n{0}\\n\".format(list(titanic_train.keys())))\n",
    "print(\"\\nTipos dos dados:\\n{0}\\n\".format(titanic_train.dtypes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-VxLKNs8-lP"
   },
   "source": [
    "### ESTATÍSTICA DESCRITIVA DOS DADOS\n",
    "\n",
    "O comando describe exibe prioritariamente os campos numéricos. Deve-se isolar os campos categóricos para serem exibidos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aCdL67o8-G_"
   },
   "outputs": [],
   "source": [
    "# Exibe apenas os campos numméricos:\n",
    "\n",
    "print(titanic_train.describe())\n",
    "\n",
    "# Para se ter uma visão dos atributos categóricos, os atributos não numéricos \n",
    "# são descartados. \n",
    "\n",
    "categ = titanic_train.dtypes[titanic_train.dtypes == \"object\"].index\n",
    "\n",
    "print(\"\\n\", titanic_train[categ].describe(), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1G0l6X1s970Q"
   },
   "source": [
    "### REMOÇÃO DE ATRIBUTOS IRRELEVANTES\n",
    "\n",
    "Os atributos ```survival``` (objetivo ou label), e atributos que descrevem os passageiros ou os agrupam em categorias são úteis e serão mantidos, por exemplo: ```Pclass```, ```Sex```, ```Age```, ```SibSp```, ```Parch```, ```Fare``` e ```Embarked```. \n",
    "\n",
    "\n",
    "* ```passengerId``` é apenas uma chave primária para identificar um passageiro e não é relevante para o problema.\n",
    "\n",
    "* ```Name``` náo é útil para previsão, mas pode ser útil para identificação dos registros ou pós-processamento (por exemplo, extrair o último nome).\n",
    "\n",
    "* ```Ticket``` não identifica o registro e nem descreve o passageiro, por isso, deve ser removido.\n",
    "\n",
    "* ```Cabin``` não identifica bem os passageiros, mas pode ser útil utilizarmos o padrão letra+numero para descrever os passageiros pelo andar do local da cabine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KheF1X787au"
   },
   "outputs": [],
   "source": [
    "del titanic_train[\"PassengerId\"]\n",
    "del titanic_train[\"Ticket\"]\n",
    "\n",
    "# Verifique que o número de atributos reduziu para 10.\n",
    "\n",
    "print(\"\\nDimensões de Titanic:\\n{0}\\n\".format(titanic_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDYqKkY1_h3I"
   },
   "source": [
    "### TRANSFORMAÇÃO DE VARIÁVEIS\n",
    "\n",
    "#### Converter numérico em categórico.\n",
    "\n",
    "Variáveis categóricas codificadas numericamente possuem baixa legibilidade. Portanto, podem ser candidatas a serem recodificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93BwzY_lABKV"
   },
   "outputs": [],
   "source": [
    "# OBSERVAÇÃO: se a base for usada para a competição do kaggle, o atributo\n",
    "# alvo, que é o campo 'survived' não deve ser recodificada.\n",
    "\n",
    "new_survived = pd.Categorical(titanic_train[\"Survived\"])\n",
    "new_survived = new_survived.rename_categories([\"Morreu\",\"Sobreviveu\"])              \n",
    "titanic_train[\"Survided\"] = new_survived\n",
    "\n",
    "new_Pclass = pd.Categorical(titanic_train[\"Pclass\"], ordered=True)\n",
    "new_Pclass = new_Pclass.rename_categories([\"1aClasse\",\"2aClasse\",\"3aClasse\"])     \n",
    "titanic_train[\"Pclass\"] = new_Pclass\n",
    "\n",
    "print(\"\\nTipos dos dados:\\n{0}\\n\".format(titanic_train.dtypes))\n",
    "categ = titanic_train.dtypes[titanic_train.dtypes == \"category\"].index\n",
    "print(\"\\n\", titanic_train[categ].describe(), sep='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTBozOeBBWV5"
   },
   "source": [
    "#### Converter atributo através de processamento de string (usando *list comprehension*).\n",
    "\n",
    "No atributo ```Cabin```,  parece que o padrão letra+número (veja exibição a seguir) indica que uma cabine pertence a algum andar, ou nível. Podemos agrupar o atributo Cabin pela letra inicial da cabine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRAcW-BSA0Yl"
   },
   "outputs": [],
   "source": [
    "#Exibe valores únicos\n",
    "\n",
    "print(\"\\nValores únicos do atributo Cabin:\",titanic_train[\"Cabin\"].unique(), sep='\\n')\n",
    "\n",
    "# Converte o dado para String\n",
    "\n",
    "char_cabin = titanic_train[\"Cabin\"].astype(str)\n",
    "\n",
    "# Pega apenas a primeira letra\n",
    "\n",
    "new_cabin = pd.Categorical([cabin[0] for cabin in char_cabin])\n",
    "titanic_train[\"Cabin\"] = new_cabin\n",
    "\n",
    "print(\"\\nValores únicos do atributo Cabin:\",titanic_train[\"Cabin\"].unique(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7npsJkQoDpZp"
   },
   "source": [
    "### VALORES OMISSOS OU INCONSISTENTES\n",
    "\n",
    "Em atributos numéricos , as possibilidades são:\n",
    "\n",
    "1. substituir por zeros;\n",
    "2. substituir por um valor médio ou mediano;\n",
    "3. estimar valores usando modelos estatísticos ou preditivos;\n",
    "4. particionar a base em registros completos e registros incompletos.\n",
    "\n",
    "Vamos analisar o atributo ```Age``` para tratarmos os valores omissos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pvbAVQYEXPX"
   },
   "outputs": [],
   "source": [
    "titanic_train.hist(column='Age',    # Coluna a ser plotada\n",
    "                   figsize=(9,6),   # Tamanho do gráfico\n",
    "                   bins=20)         # Numero de colunas do histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5z8F12WEe-R"
   },
   "source": [
    "O dado possui uma distribuição próxima da distribuição Normal. Vamos usar a mediana para preencher os valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6jgzUiNEp6O"
   },
   "outputs": [],
   "source": [
    "mediana = np.median([el for el in titanic_train[\"Age\"] if (np.isnan(el) == False)])\n",
    "\n",
    "new_age = np.where(titanic_train[\"Age\"].isnull(), # condição\n",
    "                   mediana,                       # valor se verdadeiro\n",
    "                   titanic_train[\"Age\"])          # valor se falso\n",
    "titanic_train[\"Age\"] = new_age\n",
    "\n",
    "print(\"\\nAnálise do novo atributo Age:\")\n",
    "print(titanic_train[\"Age\"].describe())\n",
    "\n",
    "titanic_train.hist(column='Age',    # Coluna a ser plotada\n",
    "                   figsize=(9,6),   # Tamanho do gráfico\n",
    "                   bins=20)         # Numero de colunas do histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDZV3WXrFBNM"
   },
   "source": [
    "### DETECTANDO OUTLIERS\n",
    "\n",
    "Outliers são valores extremos. A estatística descritiva, em geral, provê um bom indicativo da presença de outliers, com valores máximos e mínimo muito distantes; o valor da média muito próximo de um máximo ou mínimo, mostrando problema de distribuição dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV71iH7jFKVu"
   },
   "outputs": [],
   "source": [
    "titanic_train[\"Fare\"].plot(kind=\"box\", figsize=(9,9))\n",
    "\n",
    "index = np.where(titanic_train[\"Fare\"] == max(titanic_train[\"Fare\"]) )\n",
    "\n",
    "print(\"Registros com valores extremos:\",titanic_train.loc[index], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqK5TLz_Fun9"
   },
   "source": [
    "### CRIANDO NOVOS ATRIBUTOS\n",
    "\n",
    "Vamos criar uma nova variável ```Family```, que irá unir, conjude e irmãos (```SibSp```) com pais e filhos (```Parch```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qaPm_z1F-Qj"
   },
   "outputs": [],
   "source": [
    "titanic_train[\"Family\"] = titanic_train[\"SibSp\"] + titanic_train[\"Parch\"]\n",
    "\n",
    "# Encontrando quem tem a maior família À bordo\n",
    "\n",
    "most_family = np.where(titanic_train[\"Family\"] == max(titanic_train[\"Family\"]))\n",
    "\n",
    "print(\"\\nAs maiores famílias à bordo:\\n{0}\".format(titanic_train.loc[most_family]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "actaCNc3GR-k"
   },
   "source": [
    " Os atributos agora estão redundantes, ou muito correlacionados, como podemos ver com a matriz de correlação. A matriz só funciona com tipos de ddos numéricos. Será possível perceber que a variável ```Family``` terá forte correlação (acima de 0.75) com ```SibSp``` e ```Parch```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXf79w1zGX-N"
   },
   "outputs": [],
   "source": [
    "int_fields = titanic_train.dtypes[titanic_train.dtypes == \"int64\"].index\n",
    "corr = np.corrcoef(titanic_train[int_fields].transpose())\n",
    "correlacao = pd.DataFrame(data=corr, index=int_fields, columns=int_fields)\n",
    "\n",
    "print(\"\\nMatriz de correlação dos atributos inteiros:\\n{0}\".format(correlacao))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5iuM7XVFHghH"
   },
   "source": [
    "# Base de dados do Gazola de imóveis em São Paulo\n",
    "\n",
    "A base possui 14 campos: um identificador, 11 atributos e 2 rótulos (Cub e Preço $).\n",
    "\n",
    "### UPLOAD DE ARQUIVO LOCAL:\n",
    "\n",
    "Deve-se fazer o upload do arquivo \"Gazola_dados_apartamento_resumo.xls\" disponível na pasta \"Datasets\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOVJOwJcHlg2"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus\\OneDrive\\01.PythonScripts\\01.PosGraduação\\06.MachineLearning\\Unidade 1\\Transformação_de_dados\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd\n",
    "PATH = getcwd()\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTTz3rulH_5F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensões:\n",
      "(397, 14)\n",
      "\n",
      "\n",
      "Campos:\n",
      "['imóvel', 'DepEmp', 'Conserv', 'Classif', 'Elev', 'RegHom', 'Suíte', 'Garag', 'Dorm', 'Idade', 'Energia', 'Artot', 'Cub', 'Preço($)']\n",
      "\n",
      "\n",
      "Tipos dos dados:\n",
      "imóvel        int64\n",
      "DepEmp        int64\n",
      "Conserv       int64\n",
      "Classif       int64\n",
      "Elev          int64\n",
      "RegHom        int64\n",
      "Suíte         int64\n",
      "Garag         int64\n",
      "Dorm          int64\n",
      "Idade         int64\n",
      "Energia       int64\n",
      "Artot       float64\n",
      "Cub         float64\n",
      "Preço($)    float64\n",
      "dtype: object\n",
      "\n",
      "       imóvel  DepEmp  Conserv  Classif    Elev  RegHom   Suíte   Garag  \\\n",
      "count  397.00  397.00   397.00   397.00  397.00  397.00  397.00  397.00   \n",
      "mean   199.00    1.39     3.01     1.93    1.83    5.54    1.61    1.99   \n",
      "std    114.75    0.49     1.02     0.61    0.38    1.97    0.49    0.56   \n",
      "min      1.00    1.00     1.00     1.00    1.00    1.00    1.00    1.00   \n",
      "50%    199.00    1.00     3.00     2.00    2.00    6.00    2.00    2.00   \n",
      "max    397.00    2.00     4.00     3.00    2.00   11.00    3.00    3.00   \n",
      "\n",
      "         Dorm   Idade  Energia   Artot     Cub   Preço($)  \n",
      "count  397.00  397.00   397.00  397.00  397.00     397.00  \n",
      "mean     2.16    7.82   164.60  150.39    1.19   44024.67  \n",
      "std      0.51    5.86    29.02   84.75    0.36   37585.95  \n",
      "min      1.00    2.00    86.00   25.93    0.55    4130.62  \n",
      "50%      2.00    6.00   160.00  127.92    1.14   32094.04  \n",
      "max      3.00   28.00   266.00  620.73    2.61  250000.00  \n"
     ]
    }
   ],
   "source": [
    "#gazola = pd.read_excel(next(iter(uploaded.keys())), sheet_name=1)\n",
    "file_name = PATH + \"\\\\\" + \"Gazola_dados_apartamento_resumo.xlsx\"\n",
    "gazola = pd.read_excel(file_name, sheet_name=1)\n",
    "\n",
    "\n",
    "print(\"\\nDimensões:\\n{0}\\n\".format(gazola.shape))\n",
    "print(\"\\nCampos:\\n{0}\\n\".format(list(gazola.keys())))\n",
    "print(\"\\nTipos dos dados:\\n{0}\\n\".format(gazola.dtypes))\n",
    "print(gazola.describe(percentiles=[]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DefoRATFJEIW"
   },
   "source": [
    "### PREPARANDO A BASE PARA O TREINAMENTO\n",
    "\n",
    "É necessário remover o identificador, retirar o Cub e definir o preço como atributo alvo.\n",
    "\n",
    "```train_test_split``` irá separar a base em \"base de treinamento\" e \"base de teste\" a partir de uma amostragem aleatória.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjuMAt7lJPsS"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-bc91fea26e18>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-bc91fea26e18>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    X = gazola.iloc[:,1:(gazola.shape[1] - 2)]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "\n",
    "X = gazola.iloc[:,1:(gazola.shape[1] - 2)]\n",
    "\n",
    "y = gazola.iloc[:,(gazola.shape[1] - 1)]\n",
    "\n",
    "# Recupera os nomes dos atributos\n",
    "\n",
    "atributos = list(gazola)[1:(gazola.shape[1] - 2)]\n",
    "rotulo = list(gazola)[(gazola.shape[1] - 1)]\n",
    "\n",
    "# Exibe o histograma dos atributos.\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
    "plt.suptitle(\"Histograma dos atributos\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[i, j].hist(X.iloc[:,(i*3 + j)], label=atributos[i*3+j], bins=30)\n",
    "        ax[i, j].legend()\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
    "plt.suptitle(\"Histograma dos atributos\")\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        if j == 2 and i == 1:\n",
    "            ax[i, j].hist(y.iloc[:],label=rotulo,bins=30)\n",
    "        else:            \n",
    "            ax[i, j].hist(X.iloc[:,(i*3 + j+6)],label=atributos[i*3 + j+6], bins=30)\n",
    "        ax[i, j].legend()\n",
    "\n",
    "\n",
    "# Amostragem de dados\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"Base de treinamento:{0}\".format(X_train.shape))\n",
    "print(\"Base de teste:{0}\".format(X_test.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkYibP01KlDR"
   },
   "source": [
    "### TREINAMENTO POR REGRESSÃO LINEAR\n",
    "\n",
    "```fit()``` realiza o ajusto do modelo (treinamento).\n",
    "\n",
    "```predict()``` aplica o modelo sobre novos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJuZS1WkK5s2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9db4c1d7c550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acurácia da base de treinamento: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlnr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "lnr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_prev = lnr.predict(X_test)\n",
    "\n",
    "print(\"Acurácia da base de treinamento: {:.2f}\".format(lnr.score(X_train, y_train)))\n",
    "print(\"Acurácia da base de testes: {:.2f}\".format(lnr.score(X_test, y_test)))\n",
    "print(\"Descrição do modelo: \")\n",
    "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr.coef_)]\n",
    "print(\"w: {}  b: {:.2f}\".format(s, lnr.intercept_))\n",
    "print(\"Número de atributos usados: {}\".format(np.sum(lnr.coef_ != 0)))\n",
    "\n",
    "# Calcula o erro absoluto e o erro percentual da regressao linear\n",
    "errolnr = np.abs(y_test - y_prev)\n",
    "erroperc = errolnr / list(y_test)\n",
    "\n",
    "print('Erro percentual:\\n Média: {0:.2f}  Max: {1:.2f}   Min: {2:.2f}'\n",
    "      .format(np.mean(erroperc), np.max(erroperc), np.min(erroperc)))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.errorbar(np.arange(y_test.size), list(y_test), yerr=errolnr,\n",
    "             fmt='.', ecolor='r', capsize=3)\n",
    "plt.title(\"Valores reais (barras de erro de predição)\")\n",
    "plt.grid()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 4))\n",
    "plt.suptitle(\"Erros de previsão\")\n",
    "ax[0].plot(errolnr,'.')\n",
    "ax[0].set_xlabel(\"Erro absoluto\")\n",
    "ax[0].grid()\n",
    "ax[1].plot(erroperc,'.')\n",
    "ax[1].set_xlabel(\"Erro percentual\")\n",
    "ax[1].grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdqPARNoMgkS"
   },
   "source": [
    "### TRANSFORMAÇÃO DE DADOS NUMÉRICOS\n",
    "\n",
    "Vamos explorar a transformação de dados, para resolver problemas de distribuição e a normalização de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJmfmRsqMsp3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Os atributos possuem faixas de valores diferentes, que influencia os pesos \n",
    "# dos coeficientes da regressão. Vamos trabalhar melhor os atributos.\n",
    "\n",
    "X_scale = X\n",
    "\n",
    "# Iremos aplicar o logaritmo em \"Energia total\", \"Área total\" e \"Preço $\".\n",
    "\n",
    "X_scale['Energia'] = np.log10(X['Energia'])\n",
    "X_scale['Artot'] = np.log10(X['Artot'])\n",
    "y_scale = np.log10(y)\n",
    "\n",
    "# Normalização Min-Max dos dados.\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X_scale)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax[0].hist(y,bins=30, label='Preço $')\n",
    "ax[0].set_title('Preço $')\n",
    "ax[1].hist(y_scale,bins=30, label='log10(Preço $)')\n",
    "ax[1].set_title('log_10(Preço $)')\n",
    "\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scale, y_scale, test_size=0.1, random_state=0)\n",
    "\n",
    "lnr2 = LinearRegression().fit(X_train2, y_train2)\n",
    "\n",
    "y_prev2 = lnr2.predict(X_test2)\n",
    "\n",
    "errolnr2 = np.abs(y_test2 - y_prev2)\n",
    "errolnr2perc = np.abs(y_test2 - y_prev2)/y_test2\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(erroperc,'o', label='Regressão com atrib. originais')\n",
    "plt.plot(errolnr2perc,'o', label='Regressão com atrib. normalizados')\n",
    "plt.title(\"Erro de previsão (em %)\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"\\n--------------- Regressão Linear Normalizada ---------------\")\n",
    "print(\"Acurácia da base de treinamento: {:.2f}\".format(lnr2.score(X_train2, y_train2)))\n",
    "print(\"Acurácia da base de testes: {:.2f}\".format(lnr2.score(X_test2, y_test2)))\n",
    "print(\"Descrição do modelo: \")\n",
    "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr2.coef_)]\n",
    "print(\"w: {}  b: {:.2f}\".format(s, lnr2.intercept_))\n",
    "\n",
    "\n",
    "print(\"\\n------------------  Comparação de pesos   ------------------\")\n",
    "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr.coef_)]\n",
    "print(\"Original:\\n w: {}  b: {:.2f}\".format(s, lnr.intercept_))\n",
    "s = [\"{0}: {1:0.2f}\".format(a, v) for a, v in zip(atributos, lnr2.coef_)]\n",
    "print(\"Normalizado:\\n w: {}  b: {:.2f}\".format(s, lnr2.intercept_))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Transformação de dados.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
